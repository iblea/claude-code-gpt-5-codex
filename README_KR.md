<p align="center">
    <img alt="Claude Code with GPT-5 Codex"
        src="https://raw.githubusercontent.com/teremterem/claude-code-gpt-5-codex/main/images/claude-code-gpt-5-codex2.jpeg">
</p>

This repository lets you use Anthropic's **Claude Code CLI** with OpenAI models such as **GPT-5-Codex, GPT-5.1, and others** via a local LiteLLM proxy.

> **âš ï¸ ATTENTION âš ï¸**
>
> If you're here to set up `your own LiteLLM Server` with `LibreChat` as the web UI (or any other OpenAI / Anthropic API compatible client, for that matter), head over to the [litellm-server-boilerplate](https://github.com/teremterem/litellm-server-boilerplate) repository. It contains a "boilerplate" version of this repo with Claude Code CLI stuff stripped away, **an optional `LibreChat` set up, and a `README` which specifically explains how to build `your own AI agents and assistants` on top of it.**

## Quick Start âš¡

### Prerequisites

- [OpenAI API key ðŸ”‘](https://platform.openai.com/settings/organization/api-keys)
- [Anthropic API key ðŸ”‘](https://console.anthropic.com/settings/keys) - optional (if you decide not to remap some Claude models to OpenAI)
- Either [uv](https://docs.astral.sh/uv/getting-started/installation/) or [Docker Desktop](https://docs.docker.com/desktop/), depending on your preferred setup method

### First time using GPT-5 via API?

If you are going to use GPT-5 via API for the first time, **OpenAI may require you to verify your identity via Persona.** You may encounter an OpenAI error asking you to â€œverify your organization.â€ To resolve this, you can go through the verification process here:
- [OpenAI developer platform - Organization settings](https://platform.openai.com/settings/organization/general)

### Setup ðŸ› ï¸

1. **Clone this repository:**

   ```bash
   git clone https://github.com/teremterem/claude-code-gpt-5-codex.git
   cd claude-code-gpt-5-codex
   ```

2. **Configure Environment Variables:**

   Copy the template file to create your `.env`:
   ```bash
   cp .env.template .env
   ```

   Edit `.env` and add your OpenAI API key:

   ```dotenv
   OPENAI_API_KEY=your-openai-api-key-here
   # Optional: only needed if you plan to use Anthropic models
   # ANTHROPIC_API_KEY=your-anthropic-api-key-here

   # Optional (see .env.template for details):
   # LITELLM_MASTER_KEY=your-master-key-here

   # Optional: specify the remaps explicitly if you need to (the values you see
   # below are the defaults - see .env.template for more info)
   # REMAP_CLAUDE_HAIKU_TO=gpt-5.1-codex-mini-reason-none
   # REMAP_CLAUDE_SONNET_TO=gpt-5-codex-reason-medium
   # REMAP_CLAUDE_OPUS_TO=gpt-5.1-reason-high

   # Some more optional settings (see .env.template for details)
   ...
   ```

3. **Run the proxy:**

   1) **EITHER via `uv`** (make sure to install [uv](https://docs.astral.sh/uv/getting-started/installation/) first):

      **OPTION 1:** Use a script for `uv`:

      ```bash
      ./uv-run.sh
      ```

      **OPTION 2:** Run via a direct `uv` command:

      ```bash
      uv run litellm --config config.yaml
      ```

   2) **OR via `Docker`** (make sure to install [Docker Desktop](https://docs.docker.com/desktop/) first):

      **OPTION 3:** Run `Docker` in the foreground:

      ```bash
      ./run-docker.sh
      ```

      **OPTION 4:** Run `Docker` in the background:

      ```bash
      ./deploy-docker.sh
      ```

      **OPTION 5:** Run `Docker` via a direct command:

      ```bash
      docker run -d \
         --name claude-code-gpt-5 \
         -p 4000:4000 \
         --env-file .env \
         --restart unless-stopped \
         ghcr.io/teremterem/claude-code-gpt-5:latest
      ```

      > **NOTE:** To run with this command in the foreground instead of the background, remove the `-d` flag.

      To see the logs, run:

      ```bash
      docker logs -f claude-code-gpt-5
      ```

      To stop and remove the container, run:
      ```bash
      ./kill-docker.sh
      ```

      > **NOTE:** The `Docker` options above will pull the latest image from `GHCR` and will ignore all your local files except `.env`. For more detailed `Docker` deployment instructions and more options (like building `Docker` image from source yourself, using `Docker Compose`, etc.), see [docs/DOCKER_TIPS.md](docs/DOCKER_TIPS.md)

### Using with Claude Code ðŸŽ®

1. **Install Claude Code** (if you haven't already):

   ```bash
   npm install -g @anthropic-ai/claude-code
   ```

2. **Connect it to the proxy:**

   ```bash
   ANTHROPIC_BASE_URL=http://localhost:4000 claude
   ```

   If you set `LITELLM_MASTER_KEY` in your `.env` file (see `.env.template` for details), pass it as the Anthropic API key for the CLI:
   ```bash
   ANTHROPIC_API_KEY="<LITELLM_MASTER_KEY>" \
   ANTHROPIC_BASE_URL=http://localhost:4000 \
   claude
   ```

   > **NOTE:** In this case, if you've previously authenticated, run `claude /logout` first.

**That's it!** Your Claude Code client will now use the **OpenAI models** that this repo recommends by default (unless you explicitly specified different choices in your `.env` file). ðŸŽ¯

---

### Model aliases

You can find the full list of available OpenAI models in the [OpenAI API documentation](https://platform.openai.com/docs/models). Additionally, this proxy allows you to control the reasoning effort level for each model by appending it to the model name following the pattern `-reason-<effort>` (or `-reasoning-<effort>`, if you prefer). Here are some examples:

- `gpt-5.1-codex-mini-reason-none`
- `gpt-5.1-codex-mini-reason-medium`
- `gpt-5.1-codex-mini-reason-high`

If you don't specify the reasoning effort level (i.e. only specify the model name, like `gpt-5.1-codex-mini`), it will use the default level for the model.

> **NOTE:** Theoretically, you can use arbitrary models from [arbitrary providers](https://docs.litellm.ai/docs/providers), but for providers other than OpenAI or Anthropic, you will need to specify the provider as a prefix in the model name, e.g. `gemini/gemini-pro`, `gemini/gemini-pro-reason-disable` etc. (as well as set the respective API key for that provider in your `.env` file).



## SUBSCRIPTION SETTINGS

í•œêµ­ì–´ ë²„ì „ì€ `README_KR.md` ë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.

chatgptì˜ subscriptionì„ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. \
subscription í˜•íƒœì˜ í†µì‹ ì„ ìœ„í•´ì„œëŠ” ì•„ëž˜ì™€ ê°™ì€ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

ë¨¼ì €, `.env.template` íŒŒì¼ì„ `.env` íŒŒì¼ë¡œ ë³µì‚¬í•˜ì‹­ì‹œì˜¤. \
ê·¸ë¦¬ê³  `.env` íŒŒì¼ì„ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•˜ì‹­ì‹œì˜¤.

- `OPENAI_REQUEST` ë¥¼ `subscription` ìœ¼ë¡œ ì„¤ì •í•˜ì‹­ì‹œì˜¤.
- `OPENAI_API_KEY_SUBSCRIPTION`, `OPENAI_ACCOUNT_ID` ë³€ìˆ˜ë¥¼ ì„¸íŒ…í•˜ì‹­ì‹œì˜¤.
  - `OPENAI_API_KEY_SUBSCRIPTION`: access key ìž…ë ¥
  - `OPENAI_REFRESH_KEY_SUBSCRIPTION`: refresh key ìž…ë ¥
  - `OPENAI_ACCOUNT_ID`: account id ìž…ë ¥
- `ALWAYS_USE_RESPONSES_API`, `ALWAYS_USE_STREAMING` ê°’ì„ trueë¡œ ì„¤ì •í•˜ì‹­ì‹œì˜¤.

OPENAI_API_KEY_SUBSCRIPTION, OPENAI_ACCOUNT_ID ê°’ì€ codex, opencode ë“±ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ì—¬ í™•ì¸í•˜ì‹­ì‹œì˜¤.

### í”„ë¡œì íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ë¡œê·¸ì¸

```bash
./get_token_init.sh
```

#### codex ë¡œê·¸ì¸ í›„ í™•ì¸ ë°©ë²•
```bash
codex login
```

ë¡œê·¸ì¸ ì„±ê³µ ì‹œ, `$HOME/.codex/auth` ì—ì„œ "tokens.id_token", "tokens.account_id" í•„ë“œê°’ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

#### opencode ë¡œê·¸ì¸ í›„ í™•ì¸ ë°©ë²•
```
command: opencode auth login
- Click "OpenAI"
- Click "ChatGPT Pro/Plus (browser)" or "ChatGPT Pro/Plus (headless)"
```

ì´í›„, ë‹¹ì‹ ì€ `$HOME/.local/share/opencode/auth.json` ì—ì„œ "openai.access", "openai.accountId" í•„ë“œê°’ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

#### í™•ì¸ ë°©ë²•

`.env` íŒŒì¼ì—ì„œ `SYSTEM_REMINDER_REMOVE` ë³€ìˆ˜ì˜ ê°’ì„ `true` ë¡œ ì„¤ì •í•˜ì‹­ì‹œì˜¤.

```bash
export ANTHROPIC_BASE_URL="http://127.0.0.1:4000"
claude --system-prompt ''
```
ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ê°•ì œë¡œ '' ë¡œ ì£¼ìž…í•´ ì‹¤í–‰í•©ë‹ˆë‹¤. \
(claude codeì˜ ê¸°ë³¸ system prompt ì— model ì •ë³´ë¥¼ ê°•ì œ ê¸°ìž…í•˜ê¸° ë•Œë¬¸ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ì§€ ì•Šìœ¼ë©´, ëª¨ë¸ëª…ì„ ë¬¼ì—ˆì„ ë•Œ, GPT, Codex ë¼ê³  ì‘ë‹µí•˜ì§€ ì•Šì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.) \
ëª¨ë¸ ì´ë¦„ì„ ë¬¼ì–´ë´…ë‹ˆë‹¤.

#### í† í° Refresh ìˆ˜ë™ ì—…ë°ì´íŠ¸

.envì— `OPENAI_REFRESH_KEY_SUBSCRIPTION`, `OPENAI_CLIENT_ID_SUBSCRIPTION` ê°€ ì„¤ì •ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤.

```bash
./refresh.sh
```

í† í° ìžë™ ì—…ë°ì´íŠ¸ëŠ” ë‹¤ìŒ ìƒí™©ì—ì„œ ìž‘ë™í•©ë‹ˆë‹¤:

- 401 ì˜¤ë¥˜ ë°œìƒ
- í˜„ìž¬ ì‹œê°„ì´ `OPENAI_SUBSCRIPTION_EXPIRES_AT` ë§Œë£Œ ì‹œê°„ `-7 days` ë¥¼ ì§€ë‚œ ê²½ìš°
  - `OPENAI_SUBSCRIPTION_EXPIRES_AT` ê°’ì´ ë¹„ì–´ ìžˆì„ ê²½ìš°, í† í° ë§Œë£Œì‹œê°„ì„ ì²´í¬í•˜ì§€ ì•ŠëŠ”ë‹¤.


## KNOWN PROBLEM

**subscription ëª¨ë“œì— ëŒ€í•œ í† í° ê°±ì‹  í…ŒìŠ¤íŠ¸ë¥¼ í•˜ì§€ ì•Šì•„, ê°±ì‹  ê´€ë ¨ ë¡œì§ì´ ì •ìƒ ìž‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.**

**Fixed WebSearch issue in 2026.02.19.** \
**However, only temporary fixes have been applied, so the WebSearch functionality may not work fully.**

The `Web Search` tool currently does not work with this setup. You may see an error like:

```text
API Error (500 {"error":{"message":"Error calling litellm.acompletion for non-Anthropic model: litellm.BadRequestError: OpenAIException - Invalid schema for function 'web_search': 'web_search_20250305' is not valid under any of the given schemas.","type":"None","param":"None","code":"500"}}) Â· Retrying in 1 secondsâ€¦ (attempt 1/10)
```

This is planned to be fixed soon.

> **NOTE:** The `Fetch` tool (getting web content from specific URLs) is not affected and works normally.

## P. S. You are welcome to join our [MiniAgents Discord Server ðŸ‘¥](https://discord.gg/ptSvVnbwKt)

## And if you like the project, please give it a Star ðŸ’«

<p align="center">
<a href="https://www.star-history.com/#teremterem/claude-code-gpt-5-codex&type=date&legend=top-left">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=teremterem/claude-code-gpt-5-codex&type=date&theme=dark&legend=top-left" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=teremterem/claude-code-gpt-5-codex&type=date&legend=top-left" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=teremterem/claude-code-gpt-5-codex&type=date&legend=top-left" />
 </picture>
</a>
</p>
